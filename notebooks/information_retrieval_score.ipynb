{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'machine_learning'\n",
    "APPROACHES = ['auto', 'textrank', 'kea', 'rake', 'spacy_np', 'StructMineDataPipeline', 'econ']\n",
    "approach2segmentation = {}\n",
    "for approach in APPROACHES:\n",
    "    textFile = '/scratch/home/hwzha/workspace/%s/result/%s/merged.txt_without_sentence_id.evaluation.txt' % (approach, dataset)\n",
    "    with open(textFile) as fin:\n",
    "        approach2segmentation[approach] = [i for i in fin]\n",
    "        \n",
    "approach2segmentation['auto_orig'] = open('/scratch/home/hwzha/workspace/AutoPhrase/models/%s/segmentation.txt' % dataset).readlines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('econ', 0.9611568709572339)\n",
      "('auto', 0.9177718832891247)\n",
      "('rake', 0.8923076923076924)\n",
      "('kea', 0.9033581902807667)\n",
      "('StructMineDataPipeline', 0.9626934129089302)\n",
      "('spacy_np', 0.9702917771883289)\n",
      "('textrank', 0.8906540119363395)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# from conceptMining.evaluation.util import get_segmentation\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "workspaceDir = '/scratch/home/hwzha/workspace'\n",
    "dataset2queries = {\n",
    "    'pubmed': ['skin_tests', 'blood_pressures', 'bone_marrow_transplantation', 'drug_discovery', 'dna_repair'],\n",
    "    'database': ['query_language', 'hash_join', 'mysql_server', 'relational_database', 'xml_databases'],\n",
    "    'machine_learning': ['poisson_regression', 'local_search', 'local_consistency', 'global_convergence', 'belief_propagation']\n",
    "}\n",
    "approach_ap_list = []\n",
    "i = 1\n",
    "for query in dataset2queries[dataset][i:i+1]:\n",
    "# dataset2queries[dataset]:\n",
    "# ['relational_database']:\n",
    "    # = 'skin_tests'.replace(' ', '_')\n",
    "    TOPK = 50\n",
    "    information_retrievalDir =  '%s/evaluation/%s/information_retrieval' % (workspaceDir, dataset)\n",
    "\n",
    "\n",
    "    labels = []\n",
    "    valid_indexes = []\n",
    "    with open('%s/%s_%s.txt' % (information_retrievalDir, query, TOPK)) as f_in_label:\n",
    "        for i, line in enumerate(f_in_label):\n",
    "            try:\n",
    "                if not line.strip():\n",
    "                    labels.append(0)\n",
    "                    continue\n",
    "\n",
    "                if not '\\t' in line:\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    line, label = line.strip().split('\\t')\n",
    "                    if '??' in label:\n",
    "                        label = label[-1]\n",
    "                    else:\n",
    "                        label = label[0]\n",
    "                    labels.append(int(label))\n",
    "                valid_indexes.append(i)\n",
    "            except Exception as e:\n",
    "                print e\n",
    "                import ipdb; ipdb.set_trace()\n",
    "\n",
    "    labels, valid_indexes = np.array(labels), np.array(valid_indexes)\n",
    "\n",
    "    approach2scores = {}\n",
    "    with open('%s/%s_%s_order.txt'% (information_retrievalDir, query, TOPK)) as f_in_order:\n",
    "        line = f_in_order.readline()\n",
    "        indexes = line.strip().split(',')\n",
    "        indexes = [int(i) for i in indexes]\n",
    "        for line in f_in_order:\n",
    "            approach, scores = line.split('\\t')\n",
    "            scores = scores.split(',')\n",
    "\n",
    "            scores = [float(s) for s in scores]\n",
    "            scores = get_yscores(approach)\n",
    "            #  \n",
    "            approach2scores[approach] = np.array(scores)\n",
    "\n",
    "    y_true = labels\n",
    "\n",
    "    for approach, y_scores in approach2scores.items():\n",
    "        ap = average_precision_score(y_true[valid_indexes], y_scores[valid_indexes])\n",
    "        print(approach, ap)\n",
    "        approach_ap_list.append((approach, ap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('textrank', 0.9282925922483503)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('econ', 0.9354759470476546)\n",
    "('auto', 0.9146859729508992)\n",
    "('rake', 0.9137931034482759)\n",
    "('kea', 0.9385931340655975)\n",
    "('StructMineDataPipeline', 0.9604471809194345)\n",
    "('spacy_np', 0.9475463811833363)\n",
    "('textrank', 0.9282925922483503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_pairs(pairs):\n",
    "  sums = {}\n",
    "  for pair in pairs:\n",
    "    sums.setdefault(pair[0], [])\n",
    "    sums[pair[0]].append(pair[1])\n",
    "  return sums.items()\n",
    "\n",
    "\n",
    "[(approach, np.array(ap).mean()) for approach, ap in sum_pairs(approach_ap_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i,index in enumerate(indexes):\n",
    "#     print i+1,approach2segmentation['auto'][index]\n",
    "get_yscores('auto', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "get_yscores(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "get_yscores('StructMineDataPipeline', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# APPROACHES = ['auto', 'textrank', 'kea', 'rake', 'spacy_np', 'StructMineDataPipeline', 'econ']\n",
    "# approach2segmentation = {}\n",
    "# for approach in APPROACHES:\n",
    "#     textFile = '/scratch/home/hwzha/workspace/%s/result/%s/merged.txt_without_sentence_id.evaluation.txt' % (approach, dataset)\n",
    "#     with open(textFile) as fin:\n",
    "#         approach2segmentation[approach] = [i for i in fin]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_segmentation(approach='econ', index=0):\n",
    "    return approach2segmentation[approach][visualize_count]\n",
    "\n",
    "def get_yscores(approach='econ', verbose=False):\n",
    "    y_scores = []\n",
    "    for i,index in enumerate(indexes):\n",
    "        pred = int('>%s<'%query in approach2segmentation[approach][index].lower())\n",
    "        if verbose:\n",
    "            print i+1,approach2segmentation[approach][index]\n",
    "            if pred != int(y_true[i]) and i in list(valid_indexes):\n",
    "                print '!!!'\n",
    "        y_scores.append(pred)\n",
    "        \n",
    "    return y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'econ'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6a73620acb58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mvisualize_count\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapproach2segmentation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'econ'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mvisualize_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisualize_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'econ'"
     ]
    }
   ],
   "source": [
    "def visualize_by_index(index):\n",
    "    for approach in ['auto_orig', 'econ', 'StructMineDataPipeline']:\n",
    "#         if approach == 'auto':\n",
    "#             if '<c>' not in approach2segmentation[approach][index]:\n",
    "#                 break\n",
    "        print(approach)\n",
    "        print(approach2segmentation[approach][index])\n",
    "    print('--'*20)\n",
    "\n",
    "for visualize_count in np.random.randint(len(approach2segmentation['econ']), size=5):\n",
    "    visualize_by_index(visualize_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[(i,l) for i,l in enumerate (approach2segmentation['StructMineDataPipeline']) if 'leading_'  in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "approach2segmentation.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
