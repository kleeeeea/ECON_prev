{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Slow version of gensim.models.doc2vec is being used\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pdb\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from itertools import islice\n",
    "from sklearn import preprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'machine_learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbpedia_phrase_file = '/scratch/home/hwzha/workspace/dbpedia/result/{}/phrase_list_without_lower.txt'.format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inFile = '/scratch/home/klee/workspace/conceptMining/data/{}/concept_feature.txt'.format(dataset)\n",
    "modelFile = '/scratch/home/klee/workspace/conceptMining/data/{}/embedding_tmp.bin'.format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load(modelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<c>vector_machine</c>', 0.97896808385849),\n",
       " ('<c>vector_machine_SVM</c>', 0.9597148895263672),\n",
       " ('<c>machine_SVM</c>', 0.9568528532981873),\n",
       " ('<c>support_vector</c>', 0.9557873606681824),\n",
       " ('<c>support_vector_machine_SVM</c>', 0.9460259079933167),\n",
       " ('<c>vector_machines_SVM</c>', 0.9188857078552246),\n",
       " ('<c>machines_SVMs</c>', 0.9188774824142456),\n",
       " ('<c>vector_machines_SVMs</c>', 0.9182780981063843),\n",
       " ('<c>machines_SVM</c>', 0.9163370132446289),\n",
       " ('<c>vector_machines</c>', 0.9155590534210205)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('<c>support_vector_machine</c>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py:999: UserWarning: C extension compilation failed, scoring will be slow. Install a C compiler and reinstall gensim for fastness.\n",
      "  warnings.warn(\"C extension compilation failed, scoring will be slow. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-4654.07861328], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'We compare our <c>classification_algorithm</c> with <c>support_vector_machine</c>, <c>decision_tree</c> .'\n",
    "model.score(sentences=[string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py:999: UserWarning: C extension compilation failed, scoring will be slow. Install a C compiler and reinstall gensim for fastness.\n",
      "  warnings.warn(\"C extension compilation failed, scoring will be slow. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-4225.94140625], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'We compare our <c>classification_algorithm</c> with <c>vector_machine</c>, <c>decision_tree</c> .'\n",
    "model.score(sentences=[string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py:999: UserWarning: C extension compilation failed, scoring will be slow. Install a C compiler and reinstall gensim for fastness.\n",
      "  warnings.warn(\"C extension compilation failed, scoring will be slow. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-4220.56298828], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'We compare our <c>classification_algorithm</c> with <c>support_vector</c>, <c>decision_tree</c> .'\n",
    "model.score(sentences=[string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py:999: UserWarning: C extension compilation failed, scoring will be slow. Install a C compiler and reinstall gensim for fastness.\n",
      "  warnings.warn(\"C extension compilation failed, scoring will be slow. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-3792.42626953], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'We compare our <c>classification_algorithm</c> with <c>vector</c>, <c>decision_tree</c> .'\n",
    "model.score(sentences=[string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py:999: UserWarning: C extension compilation failed, scoring will be slow. Install a C compiler and reinstall gensim for fastness.\n",
      "  warnings.warn(\"C extension compilation failed, scoring will be slow. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-3825.04711914], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'We compare our <c>classification_algorithm</c> with <c>support</c>, <c>decision_tree</c> .'\n",
    "model.score(sentences=[string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py:999: UserWarning: C extension compilation failed, scoring will be slow. Install a C compiler and reinstall gensim for fastness.\n",
      "  warnings.warn(\"C extension compilation failed, scoring will be slow. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-3826.30932617], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'We compare our <c>classification_algorithm</c> with <c>machine</c>, <c>decision_tree</c> .'\n",
    "model.score(sentences=[string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature(row):\n",
    "    try:\n",
    "        if len(row) != 2:\n",
    "            return\n",
    "        text = row[1].strip()\n",
    "        res = re.split('\\s+', text[1:-1].strip())\n",
    "        res = [float(r) for r in res]\n",
    "        if len(res) == 4:\n",
    "            return res\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_dict = {}\n",
    "with open(inFile) as fin:\n",
    "    for i, line in enumerate(fin):\n",
    "        row = line.split('\\t')\n",
    "        feature = get_feature(row)\n",
    "        if feature:\n",
    "            phrase = row[0]\n",
    "            feature_dict[phrase] = feature\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dbpedia_phrase_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5ec170699c54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdbpedia_phrase_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbpedia_phrase_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_dbpedia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf_dbpedia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dbpedia_phrase_file' is not defined"
     ]
    }
   ],
   "source": [
    "SIZE = 1000\n",
    "\n",
    "dbpedia_phrase_dict = {}\n",
    "with open(dbpedia_phrase_file) as f_dbpedia:\n",
    "    for line in f_dbpedia:\n",
    "        phrase, freq = line.strip().split('\\t')\n",
    "        freq = int(freq)\n",
    "        dbpedia_phrase_dict[phrase] = freq\n",
    "\n",
    "neg_phrase = []\n",
    "for phrase in islice(reversed(list(feature_dict.keys())), random.randint(0, list(feature_dict.keys())-SIZE), SIZE):\n",
    "    if phrase in feature_dict:\n",
    "        if np.random.random() > 0.5: \n",
    "            neg_phrase.append(phrase)\n",
    "        if len(neg_phrase) > 1000:\n",
    "            break\n",
    "\n",
    "# neg_phrase = []\n",
    "# for phrase, freq in dbpedia_phrase_dict.items():\n",
    "#     if freq > 1:\n",
    "#         continue\n",
    "#     neg_phrase.append()\n",
    "\n",
    "\n",
    "pos_phrase = []\n",
    "for phrase, freq in dbpedia_phrase_dict.items():\n",
    "    if ' ' in phrase:\n",
    "        phrase = phrase.replace(' ', '_')\n",
    "        if phrase in feature_dict:\n",
    "            pos_phrase.append(phrase)\n",
    "        if len(pos_phrase) > SIZE:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<c>data_structure</c>', 0.7041827440261841),\n",
       " ('<c>data_structures</c>', 0.6953839063644409),\n",
       " ('<c>search_Indyk</c>', 0.6747983694076538),\n",
       " ('<c>similarity_search_Indyk</c>', 0.6741302609443665),\n",
       " ('<c>tree_data</c>', 0.6667823791503906),\n",
       " ('<c>LSH</c>', 0.6575652956962585),\n",
       " ('<c>hash_table</c>', 0.6497156023979187),\n",
       " ('<c>kd-tree</c>', 0.6459639072418213),\n",
       " ('hash', 0.6369410753250122),\n",
       " ('<c>same_3-step_SSH_scheme</c>', 0.6358004212379456),\n",
       " ('<c>same_3-step_SSH</c>', 0.6304434537887573),\n",
       " ('<c>neighbor_search</c>', 0.6297178864479065),\n",
       " ('<c>tree_data_structure</c>', 0.6274730563163757),\n",
       " ('<c>query_time</c>', 0.6237292289733887),\n",
       " ('<c>nearest_neighbor_search</c>', 0.619431734085083),\n",
       " ('<c>Andoni_Indyk</c>', 0.6191821098327637),\n",
       " ('<c>hashing_LSH</c>', 0.6168442368507385),\n",
       " ('<c>distance_computations</c>', 0.6167709827423096),\n",
       " ('<c>3-step_SSH_scheme</c>', 0.6160143613815308),\n",
       " ('<c>3-step_SSH</c>', 0.613584041595459),\n",
       " ('<c>minwise</c>', 0.6117804050445557),\n",
       " ('<c>lists</c>', 0.6115509271621704),\n",
       " ('<c>Query_step</c>', 0.6087397336959839),\n",
       " ('<c>exact_nearest_neighbor</c>', 0.6046912670135498),\n",
       " ('hashed', 0.6030246019363403),\n",
       " ('<c>LSH1_S</c>', 0.6027278900146484),\n",
       " ('<c>hashing</c>', 0.60142582654953),\n",
       " ('<c>KD-tree</c>', 0.5997425317764282),\n",
       " ('hashing', 0.5976970195770264),\n",
       " ('k-d', 0.5968332290649414),\n",
       " ('<c>tree_data_structures</c>', 0.5914170145988464),\n",
       " ('<c>s-step_hashing_schema</c>', 0.5905818939208984),\n",
       " ('<c>T_hash_tables</c>', 0.5900307893753052),\n",
       " ('<c>same_s-step_hashing_schema</c>', 0.5882771015167236),\n",
       " ('<c>k-d_trees</c>', 0.5851984620094299),\n",
       " ('<c>different_locality_sensitive_hash_functions</c>', 0.5846186876296997),\n",
       " ('<c>hash_functions_LSH1</c>', 0.5844360589981079),\n",
       " ('<c>same_s-step</c>', 0.5838302969932556),\n",
       " ('<c>functions_LSH1</c>', 0.5835579037666321),\n",
       " ('<c>many_e_g_,_1000_independent_hashes</c>', 0.5818750858306885),\n",
       " ('<c>many_e_g</c>', 0.5811659097671509),\n",
       " ('<c>spatial_queries</c>', 0.5790154933929443),\n",
       " ('<c>ball_trees</c>', 0.5770683288574219),\n",
       " ('<c>Indyk_and_Motwani</c>', 0.576784610748291),\n",
       " ('<c>X-trees_Berchtold_et</c>', 0.5735131502151489),\n",
       " ('<c>hashing_schema</c>', 0.5723558664321899),\n",
       " ('<c>hash</c>', 0.5721321105957031),\n",
       " ('<c>s-step_hashing</c>', 0.569014310836792),\n",
       " ('<c>same_s-step_hashing</c>', 0.5684630870819092),\n",
       " ('<c>trees_Bentley</c>', 0.5683465600013733)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('<c>hash_tables</c>', topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine_Learning',\n",
       " 'machine_learning',\n",
       " 'Artificial_Intelligence',\n",
       " 'loss_function',\n",
       " 'objective_function',\n",
       " 'optimization_problem',\n",
       " 'neural_networks',\n",
       " 'neural_network',\n",
       " 'Computer_Science',\n",
       " 'covariance_matrix']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_phrase[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nonuniform_cost',\n",
       " 'intensity_Sst',\n",
       " 'h_h_ru',\n",
       " 'global_manner_Yu',\n",
       " 'level_rejects',\n",
       " 'transformation_y_x',\n",
       " 'new_cost_sharing',\n",
       " 'training_instances_S_xi',\n",
       " 'parametric_distribution_family',\n",
       " 'Professeur_Beno']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(list(feature_dict.keys())))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nonuniform_cost',\n",
       " 'global_manner_Yu',\n",
       " 'level_rejects',\n",
       " 'transformation_y_x',\n",
       " 'new_cost_sharing',\n",
       " 'belief_PW',\n",
       " 'weighted_graph_Gk_V_k',\n",
       " 'approximate_greediness',\n",
       " 'low-dimensional_nature',\n",
       " 'position_measurements']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_phrase[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for phrase in pos_phrase:\n",
    "    X.append(feature_dict[phrase])\n",
    "    y.append(1)\n",
    "for phrase in neg_phrase:\n",
    "    X.append(feature_dict[phrase])\n",
    "    y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_normalized = preprocessing.normalize(X, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20.0, 0.80847077, 0.0, -9.0],\n",
       " [19.0, 0.79086246, 0.0, -10.0],\n",
       " [20.0, 0.84109763, 4.0, -5.0],\n",
       " [20.0, 0.76255951, 5.0, -3.0],\n",
       " [19.0, 0.71949316, 5.0, 0.0],\n",
       " [20.0, 0.82217551, 3.0, -5.0],\n",
       " [20.0, 0.77457382, 4.0, -8.0],\n",
       " [20.0, 0.77116893, 4.0, -9.0],\n",
       " [20.0, 0.78653136, 9.0, -2.0],\n",
       " [20.0, 0.74764038, 3.0, -5.0]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.91130254,  0.03683807,  0.        , -0.41008614],\n",
       "       [ 0.88431852,  0.03680917,  0.        , -0.4654308 ],\n",
       "       [ 0.95161797,  0.04002018,  0.19032359, -0.23790449],\n",
       "       [ 0.95938822,  0.03657953,  0.23984705, -0.14390823],\n",
       "       [ 0.96642671,  0.03659671,  0.25432282,  0.        ],\n",
       "       [ 0.95928395,  0.03943499,  0.14389259, -0.23982099],\n",
       "       [ 0.91230095,  0.03533222,  0.18246019, -0.36492038],\n",
       "       [ 0.89658635,  0.03457098,  0.17931727, -0.40346386],\n",
       "       [ 0.90757458,  0.03569179,  0.40840856, -0.09075746],\n",
       "       [ 0.95941309,  0.0358648 ,  0.14391196, -0.23985327]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.85441955,  0.        ,  0.35714286],\n",
       "       [ 0.95      ,  0.83581048,  0.        ,  0.28571429],\n",
       "       [ 1.        ,  0.88890073,  0.26666667,  0.64285714],\n",
       "       [ 1.        ,  0.80589896,  0.33333333,  0.78571429],\n",
       "       [ 0.95      ,  0.76038497,  0.33333333,  1.        ],\n",
       "       [ 1.        ,  0.86890319,  0.2       ,  0.64285714],\n",
       "       [ 1.        ,  0.81859609,  0.26666667,  0.42857143],\n",
       "       [ 1.        ,  0.81499769,  0.26666667,  0.35714286],\n",
       "       [ 1.        ,  0.83123323,  0.6       ,  0.85714286],\n",
       "       [ 1.        ,  0.79013191,  0.2       ,  0.64285714]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X[:10])\n",
    "display(X_normalized[:10])\n",
    "display(X_train_minmax[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train = X[:100]\n",
    "# y_train = y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = LinearSVC()\n",
    "clf = SVC(probability=True, kernel='linear')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00178072  1.48386989  0.33104146 -1.03063645]]\n",
      "[-1.00014962]\n"
     ]
    }
   ],
   "source": [
    "print(clf.coef_)\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_phrase = set(pos_phrase + neg_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_phrase = []\n",
    "X_test = []\n",
    "for phrase, feature in feature_dict.items():\n",
    "    if phrase not in train_phrase:\n",
    "        X_test_phrase.append(phrase)\n",
    "        X_test.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_score = clf.decision_function(X_test)\n",
    "y_prob = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "dataset = 'pubmed'\n",
    "score_list_path = 'score_list.bin'\n",
    "os.chdir('/scratch/home/hwzha/workspace/classifier/')\n",
    "\n",
    "# from six.moves import cPickle\n",
    "# cPickle.dump(y_prob[:,1].shape, open(score_list_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cells', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('health', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('malaria', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('thyroid', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('species', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('influenza', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('bacteria', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Africa', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('leukemia', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('lipoprotein', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('cell', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('colon', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('India', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('T', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('California', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('cyst', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('arrhythmia', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('S', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('l', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('S_aureus', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('antibiotic', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Brazil', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('nephritis', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Kenya', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('r', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Bangladesh', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Thailand', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Mexico', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('spironolactone', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('West_Africa', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('respiratory_tract_infection',\n",
       "  1,\n",
       "  array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Los_Angeles', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('benzodiazepine', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Florida', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Rwanda', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Nepal', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Egypt', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Enterobacter', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('North_Carolina', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('TMP', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Peru', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Georgia', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Cambodia', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Ghana', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('haloperidol', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Ethiopia', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Senegal', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Philippines', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('gyrus', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Milwaukee', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Nicaragua', 1, array([  3.00000090e-14,   1.00000000e+00])),\n",
       " ('Leishmania', 1, array([  3.05525779e-14,   1.00000000e+00])),\n",
       " ('thalamus', 1, array([  3.35122147e-14,   1.00000000e+00])),\n",
       " ('Maryland', 1, array([  3.46240305e-14,   1.00000000e+00])),\n",
       " ('mood_disturbance', 1, array([  4.04805760e-14,   1.00000000e+00])),\n",
       " ('cefuroxime', 1, array([  4.45078941e-14,   1.00000000e+00])),\n",
       " ('sperm', 1, array([  4.55465429e-14,   1.00000000e+00])),\n",
       " ('Atlanta', 1, array([  4.85892458e-14,   1.00000000e+00])),\n",
       " ('Branhamella_catarrhalis', 1, array([  5.18711676e-14,   1.00000000e+00])),\n",
       " ('digoxin', 1, array([  5.48308162e-14,   1.00000000e+00])),\n",
       " ('pathogen', 1, array([  5.73648903e-14,   1.00000000e+00])),\n",
       " ('colonization', 1, array([  5.86582723e-14,   1.00000000e+00])),\n",
       " ('Legionella', 1, array([  5.97987372e-14,   1.00000000e+00])),\n",
       " ('arrhythmias', 1, array([  6.04726296e-14,   1.00000000e+00])),\n",
       " ('nucleus', 1, array([  6.38989637e-14,   1.00000000e+00])),\n",
       " ('tuberculosis', 1, array([  6.50568433e-14,   1.00000000e+00])),\n",
       " ('streptococci', 1, array([  7.28098088e-14,   1.00000000e+00])),\n",
       " ('Haemophilus', 1, array([  7.75883362e-14,   1.00000000e+00])),\n",
       " ('nerve_root', 1, array([  7.91454597e-14,   1.00000000e+00])),\n",
       " ('causative_organism', 1, array([  8.02073462e-14,   1.00000000e+00])),\n",
       " ('bacilli', 1, array([  8.35293337e-14,   1.00000000e+00])),\n",
       " ('New_South', 1, array([  8.57704861e-14,   1.00000000e+00])),\n",
       " ('province', 1, array([  8.82441044e-14,   1.00000000e+00])),\n",
       " ('New_Mexico', 1, array([  1.23208979e-13,   1.00000000e+00])),\n",
       " ('isolate', 1, array([  1.25903388e-13,   1.00000000e+00])),\n",
       " ('Mycoplasma_pneumoniae', 1, array([  1.30455475e-13,   1.00000000e+00])),\n",
       " ('appendix', 1, array([  1.33412540e-13,   1.00000000e+00])),\n",
       " ('spasticity', 1, array([  1.35461377e-13,   1.00000000e+00])),\n",
       " ('Boston', 1, array([  1.44548318e-13,   1.00000000e+00])),\n",
       " ('pneumococci', 1, array([  1.47367297e-13,   1.00000000e+00])),\n",
       " ('Escherichia', 1, array([  1.51120370e-13,   1.00000000e+00])),\n",
       " ('Escherichia_coli', 1, array([  1.65885183e-13,   1.00000000e+00])),\n",
       " ('UN', 1, array([  1.87081562e-13,   1.00000000e+00])),\n",
       " ('congenital_malformations', 1, array([  1.88095746e-13,   1.00000000e+00])),\n",
       " ('fetal_death', 1, array([  1.99430978e-13,   1.00000000e+00])),\n",
       " ('Serratia', 1, array([  2.04368460e-13,   1.00000000e+00])),\n",
       " ('bovis', 1, array([  2.36631768e-13,   1.00000000e+00])),\n",
       " ('abscess', 1, array([  2.37267191e-13,   1.00000000e+00])),\n",
       " ('dyspepsia', 1, array([  2.55939745e-13,   1.00000000e+00])),\n",
       " ('Staphylococcus_aureus', 1, array([  2.76433341e-13,   1.00000000e+00])),\n",
       " ('South_America', 1, array([  2.77953514e-13,   1.00000000e+00])),\n",
       " ('methaqualone', 1, array([  3.26003813e-13,   1.00000000e+00])),\n",
       " ('antidepressants', 1, array([  3.48009626e-13,   1.00000000e+00])),\n",
       " ('microorganism', 1, array([  3.49878897e-13,   1.00000000e+00])),\n",
       " ('premedication', 1, array([  3.66404735e-13,   1.00000000e+00])),\n",
       " ('Neisseria', 1, array([  3.69055022e-13,   1.00000000e+00])),\n",
       " ('Chicago', 1, array([  3.96942352e-13,   1.00000000e+00])),\n",
       " ('Ecuador', 1, array([  4.16483672e-13,   1.00000000e+00])),\n",
       " ('enzyme_inhibitor', 1, array([  4.41137678e-13,   1.00000000e+00])),\n",
       " ('other_drugs', 1, array([  4.47782850e-13,   1.00000000e+00]))]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(X_test_phrase, y_pred, y_prob, ), key=lambda x:-x[2][1])[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_aureus 1 [  3.00000090e-14   1.00000000e+00]\n",
      "West_Africa 1 [  3.00000090e-14   1.00000000e+00]\n",
      "respiratory_tract_infection 1 [  3.00000090e-14   1.00000000e+00]\n",
      "Los_Angeles 1 [  3.00000090e-14   1.00000000e+00]\n",
      "North_Carolina 1 [  3.00000090e-14   1.00000000e+00]\n",
      "mood_disturbance 1 [  4.04805760e-14   1.00000000e+00]\n",
      "Branhamella_catarrhalis 1 [  5.18711676e-14   1.00000000e+00]\n",
      "nerve_root 1 [  7.91454597e-14   1.00000000e+00]\n",
      "causative_organism 1 [  8.02073462e-14   1.00000000e+00]\n",
      "New_South 1 [  8.57704861e-14   1.00000000e+00]\n",
      "New_Mexico 1 [  1.23208979e-13   1.00000000e+00]\n",
      "Mycoplasma_pneumoniae 1 [  1.30455475e-13   1.00000000e+00]\n",
      "Escherichia_coli 1 [  1.65885183e-13   1.00000000e+00]\n",
      "congenital_malformations 1 [  1.88095746e-13   1.00000000e+00]\n",
      "fetal_death 1 [  1.99430978e-13   1.00000000e+00]\n",
      "Staphylococcus_aureus 1 [  2.76433341e-13   1.00000000e+00]\n",
      "South_America 1 [  2.77953514e-13   1.00000000e+00]\n",
      "enzyme_inhibitor 1 [  4.41137678e-13   1.00000000e+00]\n",
      "other_drugs 1 [  4.47782850e-13   1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "for phrase, pred, score in sorted(zip(X_test_phrase, y_pred, y_prob), key=lambda x:-x[2][1])[:100]:\n",
    "    if '_' in phrase:\n",
    "        print(phrase, pred, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients_who 0.03\n",
      "risk_factors 0.61\n",
      "health_care 1.0\n",
      "United_States 0.59\n",
      "per_cent 0.06\n",
      "coronary_artery 1.0\n",
      "mm_Hg 0.98\n",
      "risk_factor 0.86\n",
      "T_cells 1.0\n",
      "control_group 0.02\n",
      "high_risk 0.29\n",
      "coronary_heart 1.0\n",
      "HIV_infection 1.0\n",
      "significant_difference 0.18\n",
      "side_effects 0.99\n",
      "artery_disease 0.99\n",
      "women_who 0.86\n",
      "interval_CI 0.68\n",
      "case_report 0.47\n",
      "confidence_interval_CI 0.4\n",
      "immunodeficiency_virus 0.98\n",
      "significant_differences 0.05\n",
      "mg_kg 0.93\n",
      "human_immunodeficiency 0.83\n",
      "growth_factor 1.0\n",
      "cancer_patients 0.99\n",
      "overall_survival 0.46\n",
      "magnetic_resonance 0.99\n",
      "clinical_features 0.89\n",
      "clinical_practice 0.28\n",
      "adverse_effects 0.08\n",
      "weight_loss 0.79\n",
      "National_Health 0.65\n",
      "Research_Council 1.0\n",
      "ClinicalTrials_gov 0.72\n",
      "National_Institute 0.16\n",
      "blood_flow 1.0\n",
      "adverse_events 0.82\n",
      "elderly_patients 0.02\n",
      "body_weight 0.22\n",
      "body_mass 0.79\n",
      "mass_index 0.86\n",
      "prospective_study 0.84\n",
      "peripheral_blood 0.7\n",
      "African_Americans 0.13\n",
      "general_population 0.05\n",
      "higher_risk 0.21\n",
      "lipoprotein_cholesterol 1.0\n",
      "diabetic_patients 0.99\n",
      "important_role 0.1\n",
      "hypertensive_patients 1.0\n",
      "mortality_rate 0.12\n",
      "consecutive_patients 0.05\n"
     ]
    }
   ],
   "source": [
    "phrase_list = []\n",
    "for phrase, pred, score in islice(zip(X_test_phrase, y_pred, y_prob), 0, 500):\n",
    "    if '_' in phrase:\n",
    "        print(phrase, round(score[1],2))\n",
    "        phrase_list.append([phrase, score[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control_group\n",
      "elderly_patients\n",
      "patients_who\n",
      "general_population\n",
      "consecutive_patients\n",
      "significant_differences\n",
      "per_cent\n",
      "adverse_effects\n",
      "important_role\n",
      "mortality_rate\n",
      "African_Americans\n",
      "National_Institute\n",
      "significant_difference\n",
      "higher_risk\n",
      "body_weight\n",
      "clinical_practice\n",
      "high_risk\n",
      "confidence_interval_CI\n",
      "overall_survival\n",
      "case_report\n",
      "United_States\n",
      "risk_factors\n",
      "National_Health\n",
      "interval_CI\n",
      "peripheral_blood\n",
      "ClinicalTrials_gov\n",
      "weight_loss\n",
      "body_mass\n",
      "adverse_events\n",
      "human_immunodeficiency\n",
      "prospective_study\n",
      "mass_index\n",
      "risk_factor\n",
      "women_who\n",
      "clinical_features\n",
      "mg_kg\n",
      "mm_Hg\n",
      "immunodeficiency_virus\n",
      "side_effects\n",
      "diabetic_patients\n",
      "cancer_patients\n",
      "magnetic_resonance\n",
      "artery_disease\n",
      "coronary_heart\n",
      "HIV_infection\n",
      "lipoprotein_cholesterol\n",
      "growth_factor\n",
      "hypertensive_patients\n",
      "Research_Council\n",
      "blood_flow\n",
      "coronary_artery\n",
      "health_care\n",
      "T_cells\n"
     ]
    }
   ],
   "source": [
    "for s in sorted(phrase_list, key=lambda x:x[1]):\n",
    "    print(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# import cPickle\n",
    "\n",
    "# from gensim.models import word2vec\n",
    "# from gensim import corpora, models, similarities\n",
    "# import sys\n",
    "# import logging\n",
    "\n",
    "\n",
    "# INITIALIZE = True\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# dataset = 'pubmed'\n",
    "\n",
    "# queries = ['database_schema', '']\n",
    "# if len(sys.argv) > 1:\n",
    "#     dataset = sys.argv[1]\n",
    "\n",
    "# APPROACHES = ['auto', 'textrank', 'kea', 'rake', 'spacy_np', 'StructMineDataPipeline']\n",
    "\n",
    "\n",
    "# def index(file_pureText):\n",
    "#     with open(file_pureText) as f:\n",
    "#         lines = f.readlines()\n",
    "\n",
    "#     logging.debug('processing %s' % file_pureText)\n",
    "#     try:\n",
    "#         if INITIALIZE:\n",
    "#             raise Exception\n",
    "#         corpus = corpora.MmCorpus(file_pureText + '.corpus')\n",
    "#         dictionary = corpora.Dictionary.load(file_pureText + '.dict')\n",
    "#         modelTfidf = models.TfidfModel.load(file_pureText + '.modelTfidf')\n",
    "#     except Exception, e:\n",
    "#         print 'using new model'\n",
    "#         wordsLists = [line.lower().split() for line in lines]\n",
    "#         dictionary = corpora.Dictionary(wordsLists)\n",
    "#         corpus = [dictionary.doc2bow(text) for text in wordsLists]\n",
    "#         modelTfidf = models.TfidfModel(corpus)\n",
    "\n",
    "#         dictionary.save(file_pureText + '.dict')  # store the dictionary, for future reference\n",
    "#         corpora.MmCorpus.serialize(file_pureText + '.corpus', corpus)  # store to disk, for later use\n",
    "#         corpus = corpora.MmCorpus(file_pureText+'.corpus')\n",
    "#         modelTfidf.save(file_pureText+'.modelTfidf')\n",
    "\n",
    "#     try:\n",
    "#         if INITIALIZE:\n",
    "#             raise Exception\n",
    "#         index = cPickle.load(open(file_pureText+'.index', 'rb'))\n",
    "#     except Exception, e:\n",
    "#         print 'using new index'\n",
    "#         modelTfidfCorpus = modelTfidf[corpus]\n",
    "#         index = similarities.Similarity(file_pureText+'.modelTfidfindex', modelTfidfCorpus, num_features=modelTfidfCorpus.corpus.num_terms)\n",
    "#         index.num_best = None\n",
    "#         cPickle.dump(index, open(file_pureText+'.index', 'wb'))\n",
    "\n",
    "#     TOPK = 100\n",
    "#     index.num_best = TOPK\n",
    "\n",
    "#     def retrieve(query, index=index, dictionary=dictionary, modelTfidf=modelTfidf):\n",
    "#         index.num_best = TOPK\n",
    "#         scores_matrix = index[modelTfidf[dictionary.doc2bow([query])]]\n",
    "\n",
    "#         P_list = getRetrievedListFromDocumentScoreMatrix(scores_matrix)\n",
    "\n",
    "#     for query in queries:\n",
    "#         retrieve\n",
    "\n",
    "#     # how to we select queries?\n",
    "\n",
    "\n",
    "# def process(dataset, approach):\n",
    "#     file_pureText = \"/scratch/home/hwzha/workspace/%s/result/%s/merged.txt_without_sentence_id.evaluation.txt\" % (approach, dataset)\n",
    "#     try:\n",
    "#         index(file_pureText)\n",
    "#     except Exception as e:\n",
    "#         print e\n",
    "\n",
    "# # for dataset in ['database', 'pubmed', 'machine_learning']:\n",
    "# for approach in APPROACHES:\n",
    "#     process(dataset, approach)\n",
    "\n",
    "\n",
    "\n",
    "#     # def evaluate_query_comparative(query_list, index=index, modelTfidf=modelTfidf, query_vectors=None, resultFileName=None):\n",
    "#     #     print '====='\n",
    "#     #     index.num_best = None\n",
    "#     #     scores_matrix = np.zeros((gen.document_size, len(query_list)))\n",
    "\n",
    "#     #     for i in range(len(query_list)):\n",
    "#     #         if not query_vectors:\n",
    "#     #             query_vector = modelTfidf[dictionary.doc2bow(query_list[i])]\n",
    "#     #         else:\n",
    "#     #             query_vector = query_vectors[i]\n",
    "#     #         scores_matrix[:, i] = index[query_vector]\n",
    "\n",
    "#     #     P_list = getRetrievedListFromDocumentScoreMatrix(scores_matrix)\n",
    "\n",
    "#     #     # from IPython import embed; embed()\n",
    "\n",
    "#     #     # import ipdb;ipdb.set_trace()\n",
    "#     #     saveAsLabels(P_list, resultFileName)\n",
    "\n",
    "#     #     return evaluate_multiClass(groundTruth_list, P_list)\n",
    "\n",
    "\n",
    "#     # # >>> import numpy as np\n",
    "#     # # >>> from sklearn.metrics import average_precision_score\n",
    "#     # # >>> y_true = np.array([0, 0, 1, 1])\n",
    "#     # # >>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "#     # # >>> average_precision_score(y_true, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/home/hwzha/anaconda3/bin/python3\r\n"
     ]
    }
   ],
   "source": [
    "! which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0.1, 1000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = x / np.log(1+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7eac435550>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxFxOQW9iIjL/R922OXA6n14oQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ea013f470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:processing /scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'rb', 'uri': '/scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.corpus.index'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='/scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.corpus.index'>}\n",
      "INFO:gensim.corpora.indexedcorpus:loaded corpus index from /scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.corpus.index\n",
      "INFO:gensim.matutils:initializing corpus reader from /scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.corpus\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'rb', 'uri': '/scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.corpus'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='/scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.corpus'>}\n",
      "INFO:gensim.matutils:accepted corpus with 5900510 documents, 669069 features, 63317810 non-zero entries\n",
      "INFO:gensim.utils:loading Dictionary object from /scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.dict\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'rb', 'uri': '/scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.dict'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='/scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.dict'>}\n",
      "INFO:gensim.utils:loaded /scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.dict\n",
      "INFO:gensim.utils:loading TfidfModel object from /scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.modelTfidf\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'rb', 'uri': '/scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.modelTfidf'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='/scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.modelTfidf'>}\n",
      "INFO:gensim.utils:loaded /scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.modelTfidf\n",
      "INFO:gensim.similarities.docsim:starting similarity index under /scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.modelTfidfindex\n",
      "DEBUG:smart_open.smart_open_lib:{'kw': {}, 'mode': 'rb', 'uri': '/scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.corpus'}\n",
      "DEBUG:smart_open.smart_open_lib:encoding_wrapper: {'errors': 'strict', 'encoding': None, 'mode': 'rb', 'fileobj': <_io.BufferedReader name='/scratch/home/hwzha/workspace/auto/result/machine_learning/merged.txt_without_sentence_id.evaluation.txt.corpus'>}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using new index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.similarities.docsim:PROGRESS: fresh_shard size=10000\n",
      "INFO:gensim.similarities.docsim:PROGRESS: fresh_shard size=20000\n",
      "INFO:gensim.similarities.docsim:PROGRESS: fresh_shard size=30000\n",
      "INFO:gensim.similarities.docsim:creating sparse index\n",
      "INFO:gensim.matutils:creating sparse matrix from corpus\n",
      "INFO:gensim.matutils:PROGRESS: at document #0/32768\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-4e8f55b574ab>\u001b[0m in \u001b[0;36mindex\u001b[0;34m(file_pureText)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pureText\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc6 in position 28: ordinal not in range(128)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-4e8f55b574ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# for dataset in ['database', 'pubmed', 'machine_learning']:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mapproach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mAPPROACHES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapproach\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-4e8f55b574ab>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(dataset, approach)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mfile_pureText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/scratch/home/hwzha/workspace/%s/result/%s/merged.txt_without_sentence_id.evaluation.txt\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mapproach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pureText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-4e8f55b574ab>\u001b[0m in \u001b[0;36mindex\u001b[0;34m(file_pureText)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'using new index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mmodelTfidfCorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelTfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pureText\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.modelTfidfindex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelTfidfCorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelTfidfCorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pureText\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/similarities/docsim.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_prefix, corpus, num_features, num_best, chunksize, shardsize, norm)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/similarities/docsim.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfresh_nnz\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdoclen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfresh_docs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshardsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_shard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfresh_docs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PROGRESS: fresh_shard size=%i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfresh_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/similarities/docsim.py\u001b[0m in \u001b[0;36mclose_shard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             index = SparseMatrixSimilarity(self.fresh_docs, num_terms=self.num_features,\n\u001b[0;32m--> 264\u001b[0;31m                                            num_docs=len(self.fresh_docs), num_nnz=self.fresh_nnz)\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMatrixSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfresh_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/similarities/docsim.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_features, num_terms, num_docs, num_nnz, num_best, chunksize, dtype, maintain_sparsity)\u001b[0m\n\u001b[1;32m    685\u001b[0m             self.index = matutils.corpus2csc(\n\u001b[1;32m    686\u001b[0m                 \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_terms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nnz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nnz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 dtype=dtype, printprogress=10000).T\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# convert to Compressed Sparse Row for efficient row slicing and multiplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/matutils.py\u001b[0m in \u001b[0;36mcorpus2csc\u001b[0;34m(corpus, num_terms, dtype, num_docs, num_nnz, printprogress)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_nnz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# HACK assume feature ids fit in 32bit integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_nnz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdocno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprintprogress\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdocno\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprintprogress\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PROGRESS: at document #%i/%i\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdocno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/similarities/docsim.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    682\u001b[0m             corpus = (matutils.scipy2sparse(v) if scipy.sparse.issparse(v) else\n\u001b[1;32m    683\u001b[0m                       (matutils.full2sparse(v) if isinstance(v, numpy.ndarray) else\n\u001b[0;32m--> 684\u001b[0;31m                        matutils.unitvec(v)) for v in corpus)\n\u001b[0m\u001b[1;32m    685\u001b[0m             self.index = matutils.corpus2csc(\n\u001b[1;32m    686\u001b[0m                 \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_terms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_docs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nnz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nnz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/gensim/matutils.py\u001b[0m in \u001b[0;36mscipy2sparse\u001b[0;34m(vec, eps)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;34m\"\"\"Convert a scipy.sparse vector into gensim document format (=list of 2-tuples).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/home/hwzha/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mget_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;34m\"\"\"Get shape of a matrix.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import cPickle\n",
    "import _pickle as cPickle\n",
    "from gensim.models import word2vec\n",
    "from gensim import corpora, models, similarities\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "\n",
    "INITIALIZE = False\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "dataset = 'machine_learning'\n",
    "\n",
    "queries = ['database_schema', '']\n",
    "# if len(sys.argv) > 1:\n",
    "#     dataset = sys.argv[1]\n",
    "\n",
    "APPROACHES = ['auto', 'textrank', 'kea', 'rake', 'spacy_np', 'StructMineDataPipeline']\n",
    "\n",
    "\n",
    "def index(file_pureText):\n",
    "    with open(file_pureText) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    logging.debug('processing %s' % file_pureText)\n",
    "    try:\n",
    "        if INITIALIZE:\n",
    "            raise Exception\n",
    "        corpus = corpora.MmCorpus(file_pureText + '.corpus')\n",
    "        dictionary = corpora.Dictionary.load(file_pureText + '.dict')\n",
    "        modelTfidf = models.TfidfModel.load(file_pureText + '.modelTfidf')\n",
    "    except Exception as e:\n",
    "        print('using new model')\n",
    "        wordsLists = [line.lower().split() for line in lines]\n",
    "        dictionary = corpora.Dictionary(wordsLists)\n",
    "        corpus = [dictionary.doc2bow(text) for text in wordsLists]\n",
    "        modelTfidf = models.TfidfModel(corpus)\n",
    "\n",
    "        dictionary.save(file_pureText + '.dict')  # store the dictionary, for future reference\n",
    "        corpora.MmCorpus.serialize(file_pureText + '.corpus', corpus)  # store to disk, for later use\n",
    "        corpus = corpora.MmCorpus(file_pureText+'.corpus')\n",
    "        modelTfidf.save(file_pureText+'.modelTfidf')\n",
    "\n",
    "    try:\n",
    "        if INITIALIZE:\n",
    "            raise Exception\n",
    "        index = cPickle.load(open(file_pureText+'.index', 'rb'))\n",
    "    except Exception as e:\n",
    "        print('using new index')\n",
    "        modelTfidfCorpus = modelTfidf[corpus]\n",
    "        index = similarities.Similarity(file_pureText+'.modelTfidfindex', modelTfidfCorpus, num_features=modelTfidfCorpus.corpus.num_terms)\n",
    "        index.num_best = None\n",
    "        cPickle.dump(index, open(file_pureText+'.index', 'wb'))\n",
    "\n",
    "    TOPK = 100\n",
    "    index.num_best = TOPK\n",
    "\n",
    "    def retrieve(query, index=index, dictionary=dictionary, modelTfidf=modelTfidf):\n",
    "        index.num_best = TOPK\n",
    "        scores_matrix = index[modelTfidf[dictionary.doc2bow([query])]]\n",
    "\n",
    "        P_list = getRetrievedListFromDocumentScoreMatrix(scores_matrix)\n",
    "\n",
    "    for query in queries:\n",
    "        retrieve\n",
    "\n",
    "    # how to we select queries?\n",
    "\n",
    "\n",
    "def process(dataset, approach):\n",
    "    file_pureText = \"/scratch/home/hwzha/workspace/%s/result/%s/merged.txt_without_sentence_id.evaluation.txt\" % (approach, dataset)\n",
    "    try:\n",
    "        index(file_pureText)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# for dataset in ['database', 'pubmed', 'machine_learning']:\n",
    "for approach in APPROACHES:\n",
    "    process(dataset, approach)\n",
    "\n",
    "\n",
    "\n",
    "    # def evaluate_query_comparative(query_list, index=index, modelTfidf=modelTfidf, query_vectors=None, resultFileName=None):\n",
    "    #     print '====='\n",
    "    #     index.num_best = None\n",
    "    #     scores_matrix = np.zeros((gen.document_size, len(query_list)))\n",
    "\n",
    "    #     for i in range(len(query_list)):\n",
    "    #         if not query_vectors:\n",
    "    #             query_vector = modelTfidf[dictionary.doc2bow(query_list[i])]\n",
    "    #         else:\n",
    "    #             query_vector = query_vectors[i]\n",
    "    #         scores_matrix[:, i] = index[query_vector]\n",
    "\n",
    "    #     P_list = getRetrievedListFromDocumentScoreMatrix(scores_matrix)\n",
    "\n",
    "    #     # from IPython import embed; embed()\n",
    "\n",
    "    #     # import ipdb;ipdb.set_trace()\n",
    "    #     saveAsLabels(P_list, resultFileName)\n",
    "\n",
    "    #     return evaluate_multiClass(groundTruth_list, P_list)\n",
    "\n",
    "\n",
    "    # # >>> import numpy as np\n",
    "    # # >>> from sklearn.metrics import average_precision_score\n",
    "    # # >>> y_true = np.array([0, 0, 1, 1])\n",
    "    # # >>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "    # # >>> average_precision_score(y_true, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'machine_learning'\n",
    "queries = ['database_schema', '']\n",
    "# if len(sys.argv) > 1:\n",
    "#     dataset = sys.argv[1]\n",
    "\n",
    "APPROACHES = ['auto', 'textrank', 'kea', 'rake', 'spacy_np', 'StructMineDataPipeline']\n",
    "\n",
    "approach = APPROACHES[0]\n",
    "file_pureText = \"/scratch/home/hwzha/workspace/%s/result/%s/merged.txt_without_sentence_id.evaluation.txt\" % (approach, dataset)\n",
    "# with codecs.open(file_pureText+'.index', mode='rb', encoding='utf-8') as fin:\n",
    "#     index = cPickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc6 in position 28: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-48c66da49964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pureText\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc6 in position 28: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "cPickle.load(open(file_pureText+'.index', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "dataset = 'machine_learning'\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "# import cPickle\n",
    "import _pickle as cPickle\n",
    "# sys.path.append('/scratch/home/klee/workspace/')\n",
    "# from conceptMining.embedding.embedding import display_concept\n",
    "# if len(sys.argv) > 1:\n",
    "#     dataset = sys.argv[1]\n",
    "def display_concept(w):\n",
    "    return re.sub(r'<?/c>', '', w)\n",
    "\n",
    "approach2concept2score = {}\n",
    "\n",
    "GENERATE_GROUND_TRUTH = 1\n",
    "APPROACHES = ['auto', 'textrank', 'kea', 'rake', 'spacy_np', 'StructMineDataPipeline']\n",
    "\n",
    "for approach in APPROACHES:\n",
    "    concept2score_file = \"/scratch/home/hwzha/workspace/%s/result/%s/phrase_list_relative.txt\" % (approach, dataset)\n",
    "\n",
    "    concept2score = {}\n",
    "    for l in open(concept2score_file):\n",
    "        concept, score = l.strip().split('\\t')\n",
    "        score = float(score)\n",
    "        concept2score[concept] = score\n",
    "        # concept2score.append((concept, score))\n",
    "\n",
    "    approach2concept2score[approach] = concept2score\n",
    "\n",
    "common_concepts = set.intersection(*[set(concept2score.keys()) for concept2score in approach2concept2score.values()])\n",
    "\n",
    "\n",
    "approach2concept2score_difference = {}\n",
    "for approach in approach2concept2score:\n",
    "    concept2score_difference = {concept: score for concept, score in approach2concept2score[approach].items() if concept not in common_concepts}\n",
    "    approach2concept2score_difference[approach] = concept2score_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for concept, explanation in islice(concept2explaination.items(),0, 50):\n",
    "     print(concept, '\\n', explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
