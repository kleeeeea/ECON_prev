{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82011\n",
      "----------------------------------------\n",
      "293632\n",
      "auto\n",
      "The hierarchical <c>pattern_graph</c> , HP G Q V , E , AN , is a <c>labeled_directed_graph</c> with V the nodes , E the <c>direct_edges</c> and AN the annotations associated with edges .\n",
      "\n",
      "econ\n",
      "The <c>graph</c> <c>Q_V</c> <c>E</c> <c>AN</c> is a labeled directed <c>graph</c> with <c>V</c> the <c>nodes</c> <c>E</c> the <c>direct_edges</c> and AN the <c>annotations</c> associated with <c>edges</c>\n",
      "\n",
      "----------------------------------------\n",
      "1240849\n",
      "----------------------------------------\n",
      "1588732\n",
      "----------------------------------------\n",
      "1312795\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/cs/student/klee/ve/lib/python2.7/site-packages/')\n",
    "\n",
    "import sys\n",
    "import random\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import cPickle\n",
    "# import _pickle as cPickle\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim import corpora, models, similarities\n",
    "import logging\n",
    "import pdb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "dataset = 'database'\n",
    "workspaceDir = '/scratch/home/hwzha/workspace'\n",
    "query = 'xml_databases'.replace(' ', '_')\n",
    "TOPK = 50\n",
    "information_retrievalDir = '%s/evaluation/%s/information_retrieval' % (workspaceDir, dataset)\n",
    "\n",
    "APPROACHES = ['auto', 'textrank', 'kea', 'rake', 'spacy_np', 'StructMineDataPipeline', 'econ']\n",
    "\n",
    "# visualize segmentations of each approach\n",
    "approach2segmentation = {}\n",
    "for approach in APPROACHES:\n",
    "    textFile = '/scratch/home/hwzha/workspace/%s/result/%s/merged.txt_without_sentence_id.evaluation.txt' % (approach, dataset)\n",
    "    with open(textFile) as fin:\n",
    "        approach2segmentation[approach] = [i for i in fin]\n",
    "\n",
    "lineCount = len(approach2segmentation[approach])\n",
    "\n",
    "for visualize_count in np.random.randint(lineCount, size=5):\n",
    "    print(visualize_count)\n",
    "    for approach in ['auto', 'econ']:\n",
    "        if approach == 'auto':\n",
    "            if '<c>' not in approach2segmentation[approach][visualize_count]:\n",
    "                break\n",
    "        print(approach)\n",
    "        print(approach2segmentation[approach][visualize_count])\n",
    "    print('--'*20)\n",
    "\n",
    "\n",
    "def retrieve(query, approach, approach2segmentation=approach2segmentation, topN=None):\n",
    "    if approach in ['StructMineDataPipeline', 'rake', 'econ', 'kea']:\n",
    "        query_re = re.compile(r'<c>%s<\\/c>' % query)\n",
    "    else:\n",
    "        query_re = re.compile('\\b%s\\b' % query)\n",
    "    # wrapped_query_re = re.crompile(r'<c>%s<\\/c>' % query)\n",
    "    if topN:\n",
    "        return [i for i, l in enumerate(approach2segmentation[approach]) if query_re.search(l)][:topN]\n",
    "\n",
    "    return [i for i, l in enumerate(approach2segmentation[approach]) if query_re.search(l)]\n",
    "\n",
    "# information retrieval\n",
    "\n",
    "# texts\n",
    "textFile = '/scratch/home/hwzha/data/%s/merged.txt_without_sentence_id' % dataset\n",
    "with open(textFile) as fin:\n",
    "    texts = [i for i in fin]\n",
    "\n",
    "# now retrieve score list of all documents\n",
    "def retrieve_scores(query, file_pureText, dictionary, modelTfidf):\n",
    "    index = cPickle.load(open(file_pureText+'.index', 'rb'))\n",
    "    scores_matrix = index[modelTfidf[dictionary.doc2bow([query])]]\n",
    "    scores_matrix = np.array(scores_matrix)\n",
    "    return scores_matrix\n",
    "\n",
    "def remove_marker(text):\n",
    "    return re.subn(pattern='</?c>',string=text, repl='')[0]\n",
    "def wrap_marker(text):\n",
    "    text = re.subn(pattern='</?c>',string=text, repl='')[0]\n",
    "    return '<c>' + text + '</c>'\n",
    "\n",
    "def get_line_count(inFile):\n",
    "    count = -1\n",
    "    for count, line in enumerate(open(inFile, 'r')):\n",
    "        pass\n",
    "    count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:47<00:00,  6.82s/it]\n",
      "100%|██████████| 7/7 [00:46<00:00,  6.66s/it]\n"
     ]
    }
   ],
   "source": [
    "APPROACHES = ['auto', 'textrank', 'kea', 'rake', 'spacy_np', 'StructMineDataPipeline', 'econ']\n",
    "approach2indexes = {}\n",
    "\n",
    "for approach in tqdm(APPROACHES):\n",
    "    # if approach in ['StructMineDataPipeline', 'rake', 'econ', 'kea']:\n",
    "    #     query = wrap_marker(query)\n",
    "\n",
    "    file_pureText = \"%s/%s/result/%s/merged.txt_without_sentence_id.evaluation.txt\" % (workspaceDir, approach, dataset)\n",
    "    corpus = corpora.MmCorpus(file_pureText + '.corpus')\n",
    "    dictionary = corpora.Dictionary.load(file_pureText + '.dict')\n",
    "    modelTfidf = models.TfidfModel.load(file_pureText + '.modelTfidf')\n",
    "\n",
    "    # scores_matrix = retrieve(query, file_pureText=file_pureText, dictionary=dictionary, modelTfidf=modelTfidf)\n",
    "    # retreived_indexes = scores_matrix.argsort()[-TOPK:][::-1] # first pass retrieved indexes\n",
    "    retreived_indexes = retrieve(query, approach, topN=TOPK)\n",
    "    approach2indexes[approach] = retreived_indexes\n",
    "    # query = remove_marker(query)\n",
    "\n",
    "common_indexes = set.intersection(*[set(approach2indexes[approach]) for approach in APPROACHES])\n",
    "all_retreived_indexes = []\n",
    "for approach in APPROACHES:\n",
    "    retreived_indexes = [index for index in approach2indexes[approach] if index not in common_indexes]\n",
    "    all_retreived_indexes.extend(retreived_indexes)\n",
    "all_retreived_indexes = list(set(all_retreived_indexes))\n",
    "\n",
    "#second pass retrieve scores\n",
    "approach2scores = {}\n",
    "for approach in tqdm(APPROACHES):\n",
    "    if approach in ['StructMineDataPipeline', 'rake', 'econ', 'kea']:\n",
    "        query = wrap_marker(query)\n",
    "\n",
    "    file_pureText = \"%s/%s/result/%s/merged.txt_without_sentence_id.evaluation.txt\" % (workspaceDir, approach, dataset)\n",
    "    corpus = corpora.MmCorpus(file_pureText + '.corpus')\n",
    "    dictionary = corpora.Dictionary.load(file_pureText + '.dict')\n",
    "    modelTfidf = models.TfidfModel.load(file_pureText + '.modelTfidf')\n",
    "    scores_matrix = retrieve_scores(query, file_pureText, dictionary=dictionary, modelTfidf=modelTfidf)\n",
    "    all_scores = scores_matrix[all_retreived_indexes] # scores of all_retreived_indexes\n",
    "    approach2scores[approach] = all_scores\n",
    "    query = remove_marker(query)\n",
    "\n",
    "with open('%s/%s_%s.txt' % (information_retrievalDir, query, TOPK), 'w') as f_out, \\\n",
    "    open('%s/%s_%s_explanation.txt' % (information_retrievalDir, query, TOPK), 'w') as f_out_explanation:\n",
    "        for i, index in enumerate(all_retreived_indexes):\n",
    "            score_explanation = []\n",
    "            for approach in APPROACHES:\n",
    "                score_explanation.append(approach + ':' + str(approach2scores[approach][i]))\n",
    "            score_explanation = ','.join(score_explanation)\n",
    "            f_out.write(texts[index])\n",
    "            f_out_explanation.write(texts[index].strip() + '\\t' + str(index) + '\\t' + score_explanation + '\\n')\n",
    "\n",
    "with open('%s/%s_%s_order.txt' % (information_retrievalDir, query, TOPK), 'w') as f_out_order:\n",
    "    indexs = [str(i) for i in all_retreived_indexes]\n",
    "    f_out_order.write(','.join(indexs) + '\\n')\n",
    "    for approach in APPROACHES:\n",
    "        scores = approach2scores[approach].tolist()\n",
    "        scores = [str(s) for s in scores]\n",
    "        f_out_order.write(approach + '\\t'  + ','.join(scores) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_autophrase_output = \"/scratch/home/hwzha/workspace/AutoPhrase/models/%s/segmentation.txt\" % (dataset)\n",
    "auto_text = []\n",
    "with open(raw_autophrase_output) as f:\n",
    "    for line in f:\n",
    "        auto_text.append(line.replace('<phrase>', '<c>').replace('</phrase>', '</c>'))\n",
    "approach2segmentation['auto'] = auto_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438725\n",
      "auto\n",
      "Even though <c>PR</c> and <c>PB</c> can remove more <c>false candidates</c> , this does not compensate the cost of <c>index traversal</c> .\n",
      "\n",
      "econ\n",
      "Even though <c>PR</c> and <c>PB</c> can remove <c>false_candidates</c> this does not compensate the <c>cost</c> of <c>index_traversal</c>\n",
      "\n",
      "StructMineDataPipeline\n",
      "Even though <c>PR</c> and <c>PB</c> can remove more <c>false_candidates</c> , this does not compensate the <c>cost</c> of <c>index_traversal</c> .\n",
      "\n",
      "----------------------------------------\n",
      "1354131\n",
      "auto\n",
      "We start by studying the performance of numeric algorithms binary-shrink and <c>rank-shrink</c> in Section 2 , using dataset <c>Adult</c>-numeric .\n",
      "\n",
      "econ\n",
      "We start by studying the <c>performance</c> of <c>algorithms_binary-shrink</c> and <c>rank-shrink</c> in <c>Section</c> using <c>Adult-numeric</c>\n",
      "\n",
      "StructMineDataPipeline\n",
      "We start by studying the <c>performance</c> of <c>numeric_algorithms_binary-shrink</c> and <c>rank-shrink</c> in <c>Section</c> 2 , using dataset <c>Adult-numeric</c> .\n",
      "\n",
      "----------------------------------------\n",
      "1049658\n",
      "auto\n",
      "The <c>index interaction</c> component embeds to our system the functionality of two database <c>tuning tools</c> introduced by Schnaitter et al .\n",
      "\n",
      "econ\n",
      "The <c>index_interaction_component</c> embeds to our <c>system</c> the <c>functionality</c> of two <c>tuning_tools</c> introduced by <c>et_al</c>\n",
      "\n",
      "StructMineDataPipeline\n",
      "The <c>index_interaction_component</c> embeds to our <c>system</c> the <c>functionality</c> of two <c>database_tuning_tools</c> introduced by <c>Schnaitter</c> et <c>al</c> .\n",
      "\n",
      "----------------------------------------\n",
      "647008\n",
      "auto\n",
      "From the convex hull of p5 , p6 , p7 , <c>pk</c> , we keep in F the three facets <c>incident to pk</c> , i e , <c>pk</c> , p5 , p6 , <c>pk</c> , p6 , p7 , and <c>pk</c> , p7 , p5 .\n",
      "\n",
      "econ\n",
      "From the <c>convex_hull</c> of p5 <c>p6</c> <c>p7</c> pk we keep in <c>F</c> the three <c>facets_incident</c> to pk i e pk p5 <c>p6</c> pk <c>p6</c> <c>p7</c> and pk p7 p5\n",
      "\n",
      "StructMineDataPipeline\n",
      "From the <c>convex_hull</c> of <c>p5</c> , <c>p6</c> , <c>p7</c> , <c>pk</c> , we keep in <c>F</c> the three <c>facets</c> incident to pk , i <c>e</c> , <c>pk</c> , <c>p5</c> , <c>p6</c> , <c>pk</c> , <c>p6</c> , <c>p7</c> , and <c>pk</c> , <c>p7</c> , <c>p5</c> .\n",
      "\n",
      "----------------------------------------\n",
      "799350\n",
      "auto\n",
      "the set of top entities that were discussed by people on <c>social media</c> each day , as identified by Grapevine24 .\n",
      "\n",
      "econ\n",
      "the <c>set</c> of <c>top_entities</c> that were discussed by <c>people</c> on <c>social_media</c> each <c>day</c> as identified by <c>Grapevine24</c>\n",
      "\n",
      "StructMineDataPipeline\n",
      "the <c>set</c> of <c>top_entities</c> that were discussed by <c>people</c> on <c>social_media</c> each <c>day</c> , as identified by <c>Grapevine24</c> .\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for visualize_count in np.random.randint(lineCount, size=5):\n",
    "    print(visualize_count)\n",
    "    for approach in ['auto', 'econ', 'StructMineDataPipeline']:\n",
    "        if approach == 'auto':\n",
    "            if '<c>' not in approach2segmentation[approach][visualize_count]:\n",
    "                break\n",
    "        print(approach)\n",
    "        print(approach2segmentation[approach][visualize_count])\n",
    "    print('--'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2",
   "language": "python",
   "name": "py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
