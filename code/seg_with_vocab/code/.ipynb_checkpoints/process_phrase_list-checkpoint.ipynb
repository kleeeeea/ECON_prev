{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workspaceDir = '/home/hanwen/disk/workspace'\n",
    "dataset = 'test'\n",
    "phraseinFile = '{workspaceDir}/AutoPhrase/models/{dataset}/AutoPhrase.txt'.format(\n",
    "    workspaceDir=workspaceDir, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def read_autophrase_list(inFile, threshold=0.5):\n",
    "# #     for test\n",
    "# #     inFile = phraseinFile\n",
    "# #     threshold = 0.5\n",
    "#     with open(inFile, 'r') as fin:\n",
    "#         phrase_list = []\n",
    "#         for line in fin:\n",
    "#             phrase = line.split('\\t')[1].strip()\n",
    "#             score = float(line.split('\\t')[0])\n",
    "#             phrase_list.append((phrase, score))\n",
    "#             if score < threshold:\n",
    "#                 break\n",
    "#     return phrase_list\n",
    "\n",
    "# def read_rake_list(inFile, threshold, phraseFirst=True):\n",
    "#     with open(inFile, 'r') as fin:\n",
    "#         phrase_list = []\n",
    "#         for line in fin:\n",
    "#             phrase = line.split('\\t')[0].strip()\n",
    "#             score = float(line.split('\\t')[1])\n",
    "#             if score >= threshold:\n",
    "#                 phrase_list.append((phrase, score))\n",
    "#         return phrase_list\n",
    "\n",
    "\n",
    "# method = 'textrank'\n",
    "# phraseinFile = '{workspaceDir}/{method}/{dataset}_{method}_term.txt'.format(\n",
    "#     workspaceDir=workspaceDir, method=method, dataset=dataset)\n",
    "# phrase_list = read_rake_list(phraseinFile, 0)\n",
    "# phrase_list_sorted = sorted(phrase_list, key=itemgetter(1), reverse=True)\n",
    "\n",
    "# phrase_list_sorted_ = []\n",
    "# for phrase in phrase_list_sorted:\n",
    "#     phrase_len = len(phrase[0].split(' '))\n",
    "#     if phrase_len <= 6 and phrase_len > 1:\n",
    "#         phrase_list_sorted_.append(phrase)\n",
    "\n",
    "# phraseinFile = '{workspaceDir}/AutoPhrase/models/{dataset}/AutoPhrase.txt'.format(\n",
    "#     workspaceDir=workspaceDir, dataset=dataset)\n",
    "# phrase_list = read_autophrase_list(phraseinFile, 0.5)\n",
    "# phrase_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_phrase_list(inFile, threshold, phraseFirst=True, min_phrase_len=2, max_phrase_len=6):\n",
    "    if phraseFirst:\n",
    "        phrase_idx = 0\n",
    "        score_idx = 1\n",
    "    else:\n",
    "        phrase_idx = 1\n",
    "        score_idx = 0\n",
    "    try:\n",
    "        with open(inFile, 'r') as fin:\n",
    "            phrase_list = []\n",
    "            for line in fin:\n",
    "                phrase = line.split('\\t')[phrase_idx].strip()\n",
    "                score = float(line.split('\\t')[score_idx])\n",
    "                phrase_list.append((phrase, score))\n",
    "\n",
    "            phrase_list_sorted = sorted(phrase_list, key=itemgetter(1), reverse=True)\n",
    "            phrase_list_sorted_ = []\n",
    "            for phrase in phrase_list_sorted:\n",
    "                phrase_len = len(phrase[0].split(' '))\n",
    "                if phrase_len <= max_phrase_len and phrase_len >= min_phrase_len:\n",
    "                    phrase_list_sorted_.append(phrase)\n",
    "            return phrase_list_sorted_\n",
    "    except FileNotFoundError as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_phrase_list(phrase_list, outFile):\n",
    "    if phrase_list:\n",
    "        outDir = os.path.dirname(os.path.realpath(outFile))\n",
    "        if not os.path.exists(outDir):\n",
    "            os.makedirs(outDir)\n",
    "        with open(outFile, 'w') as fout:\n",
    "            for p in phrase_list:\n",
    "                fout.write(p[0] + '\\t' + str(p[1]))\n",
    "                fout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:41<00:00,  8.35s/it]\n"
     ]
    }
   ],
   "source": [
    "for dataset in tqdm(['test', 'nips', 'pubmed', 'JMLR', 'database']):\n",
    "    method = 'auto'\n",
    "    phraseinFile = '{workspaceDir}/AutoPhrase/models/{dataset}/AutoPhrase.txt'.format(\n",
    "        workspaceDir=workspaceDir, method=method, dataset=dataset)\n",
    "    phrase_list = read_phrase_list(phraseinFile, threshold=0.0, phraseFirst=False,min_phrase_len=2, max_phrase_len=6)\n",
    "    # phrase_list[:10]\n",
    "    phraseoutFile = '{workspaceDir}/{method}/result/{dataset}/phrase_list.txt'.format(\n",
    "        workspaceDir=workspaceDir, method=method, dataset=dataset)\n",
    "    save_phrase_list(phrase_list, phraseoutFile)\n",
    "\n",
    "    method = 'textrank'\n",
    "    phraseinFile = '{workspaceDir}/{method}/{dataset}_{method}_term.txt'.format(\n",
    "        workspaceDir=workspaceDir, method=method, dataset=dataset)\n",
    "    phrase_list = read_phrase_list(phraseinFile, threshold=0.0, phraseFirst=True,min_phrase_len=2, max_phrase_len=6)\n",
    "    # phrase_list[:10]\n",
    "    phraseoutFile = '{workspaceDir}/{method}/result/{dataset}/phrase_list.txt'.format(\n",
    "        workspaceDir=workspaceDir, method=method, dataset=dataset)\n",
    "    save_phrase_list(phrase_list, phraseoutFile)\n",
    "\n",
    "    method = 'rake'\n",
    "    phraseinFile = '{workspaceDir}/{method}/{dataset}_{method}_term0.txt'.format(\n",
    "        workspaceDir=workspaceDir, method=method, dataset=dataset)\n",
    "    phrase_list = read_phrase_list(phraseinFile, threshold=0.0, phraseFirst=True,min_phrase_len=2, max_phrase_len=6)\n",
    "#     phrase_list[:10]\n",
    "    phraseoutFile = '{workspaceDir}/{method}/result/{dataset}/phrase_list.txt'.format(\n",
    "        workspaceDir=workspaceDir, method=method, dataset=dataset)\n",
    "    save_phrase_list(phrase_list, phraseoutFile)\n",
    "\n",
    "    method = 'kea'\n",
    "    phraseinFile = '{workspaceDir}/{method}/{dataset}_{method}_term.txt'.format(\n",
    "        workspaceDir=workspaceDir, method=method, dataset=dataset)\n",
    "    phrase_list = read_phrase_list(phraseinFile, threshold=0.0, phraseFirst=True,min_phrase_len=2, max_phrase_len=6)\n",
    "    # phrase_list[:10]\n",
    "    phraseoutFile = '{workspaceDir}/{method}/result/{dataset}/phrase_list.txt'.format(\n",
    "        workspaceDir=workspaceDir, method=method, dataset=dataset)\n",
    "    save_phrase_list(phrase_list, phraseoutFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
